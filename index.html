<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hand Gesture-Based Volume Control</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Hand Gesture-Based Volume Control </h1>
        <p>Using Computer Vision and Machine Learning</p>
    </header>
    <main>
        <section class="project-description">
            <h2>Project Overview</h2>
            <p>

This project utilizes computer vision and machine learning to control volume levels using hand gestures.</p>

<p>This project demonstrates a innovative application of computer vision and machine learning in controlling volume levels using hand gestures. With further enhancements, this system can be integrated into various devices and applications, providing a convenient and intuitive user experience.</p>
            <p>It utilizes OpenCV, MediaPipe, and PyAutoGUI libraries to detect hand landmarks and adjust volume settings accordingly.</p>
        </section>
        <section class="project-demo">
            <h2>Project Demo</h2>
            <video width="640" height="480" controls>
            <source src="Project.mp4" type="video/mp4">
            
            </video>
        </section>
        <section class="project-code">
            <h2>Project Code</h2>
            <pre>
                <code>
import cv2
import mediapipe as mp
import pyautogui
from scipy.spatial import distance_matrix

x1 = y1 = x2 = y2 = 0
webcam = cv2.VideoCapture(0)
my_hands = mp.solutions.hands.Hands()
drawing_utils = mp.solutions.drawing_utils
while True:
    _ , image = webcam.read()
    image = cv2.flip(image,1)
    frame_height, frame_width, _ = image.shape

    rgb_image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
    output = my_hands.process(rgb_image)
    hands = output.multi_hand_landmarks
    if hands:
        for hand in hands:
            drawing_utils.draw_landmarks(image,hand)
            landmarks = hand.landmark
            for id, landmark in enumerate(landmarks):
                x = int(landmark.x * frame_width)
                y = int(landmark.y * frame_height)
                if id == 8:
                    cv2.circle(img=image,center=(x,y),radius=8,color=(0,255,255),thickness=3)
                    x1 = x
                    y1 = y
                if id == 4:
                    cv2.circle(img=image,center=(x,y),radius=8,color=(0,0,255),thickness=3)
                    x2 = x
                    y2 = y
        dist = ((x2-x1)**2 + (y2-y1)**2)**0.5//4
        cv2.line(image,(x1,y1),(x2,y2),(0,255,0),5)
        if dist > 25:
            pyautogui.press("volumeup")
        else:
            pyautogui.press("volumedown")


    cv2.imshow("Hand volume control using python", image)
    key = cv2.waitKey(10)
    if key == 27:
        break
webcam.release()
cv2.destroyAllWindows()
                </code>
            </pre>
        </section>
    </main>
    <footer>
        <p>Created by @Anurudha Sarkar</p>
    </footer>
    <script src="script.js"></script>
</body>
</html>
